{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepctr-torch\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,MultiLabelBinarizer,MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from deepctr_torch.inputs import SparseFeat, get_feature_names, DenseFeat\n",
    "from deepctr_torch.models import DeepFM\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor,plot_importance,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Train 파일 로드\n",
    "Ori_Train = pd.read_csv('./Train/Train.csv',encoding='utf-8')\n",
    "# 엑셀파일이기에 read_excel로 로드\n",
    "Sub_Data = pd.read_excel('./Train/ETC_Data/Main_Subjects.xlsx')\n",
    "\n",
    "# Primary Key 별로 진료과목 정리\n",
    "Sub_Data = Sub_Data.groupby(['암호화요양기호'])['진료과목코드명'].apply(','.join).reset_index()\n",
    "Sub_Data['진료과목코드명']=Sub_Data['진료과목코드명'].apply(lambda x: sorted(set(x.split(','))))\n",
    "\n",
    "# Data Merge\n",
    "Merged_Train=pd.merge(Ori_Train,Sub_Data,left_on='HOSPITAL_CD',right_on='암호화요양기호',how='left')\n",
    "# Na값 처리\n",
    "Merged_Train['진료과목코드명']=Merged_Train['진료과목코드명'].fillna('X')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muliti Label Onehot\n",
    "mlb = MultiLabelBinarizer()\n",
    "Encoded_Value = mlb.fit_transform(Merged_Train['진료과목코드명'])\n",
    "Hospital_Class = mlb.classes_\n",
    "Hospital_Class = ['진료과목'+'_'+k for k in Hospital_Class]\n",
    "One_Hot_Classes=pd.DataFrame(Encoded_Value,columns=Hospital_Class)\n",
    "Merged_Train= Merged_Train.drop('진료과목코드명',axis=1)\n",
    "\n",
    "\n",
    "Refined_Train = pd.concat([Merged_Train,One_Hot_Classes],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 활용할 모든 Column\n",
    "ALL_FIELDS = ['USER_ID','HOSPITAL_ID','시군구코드','x좌표','y좌표']\n",
    "# 학습에 활용할 모든 Column\n",
    "Subject_FIELDS = [k for k in Refined_Train.columns if k.startswith('진료과목')]\n",
    "# 연속형 변수가 담긴 Column\n",
    "CONT_FIELDS = ['x좌표','y좌표']\n",
    "# 범주형 변수가 담긴 Column > One Hot Encoding으로 변경해야함\n",
    "CAT_FIELDS = list(set(ALL_FIELDS).difference(CONT_FIELDS))+Subject_FIELDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "Refined_Train[CONT_FIELDS] = mms.fit_transform(Refined_Train[CONT_FIELDS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in CAT_FIELDS:\n",
    "    lbe = LabelEncoder()\n",
    "    Refined_Train[feat] = lbe.fit_transform(Refined_Train[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat,Refined_Train[feat].nunique()) for feat in CAT_FIELDS] + [DenseFeat(feat,1,)for feat in CONT_FIELDS]\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "DeepFM_Train_Columns=get_feature_names(fixlen_feature_columns)\n",
    "DeepFM_Train_Columns.append('TOTAL_RATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train = Refined_Train[DeepFM_Train_Columns]\n",
    "Final_Train[Final_Train.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train=Final_Train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Train[Final_Train.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(Final_Train, test_size=0.2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "model = DeepFM(linear_feature_columns,dnn_feature_columns,task='regression',device=device,dnn_dropout=0.5)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'mse',\n",
    "              metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_input = {name: train[name]for name in DeepFM_Train_Columns}\n",
    "test_model_input = {name: valid[name]for name in DeepFM_Train_Columns}\n",
    "\n",
    "\n",
    "history = model.fit(train_model_input, train['TOTAL_RATE'].values, batch_size=1024, epochs=20, verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 결과 출력\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_mse\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train_loss\", \"val_loss\"], loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_value = model.predict(test_model_input, 1024)\n",
    "predict = np.around(pred_value)\n",
    "answer=test_model_input['TOTAL_RATE']\n",
    "mean_squared_error(answer,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in CAT_FIELDS:\n",
    "    Final_Train[k]=Final_Train[k].astype('category')\n",
    "    \n",
    "    \n",
    "lgbm_train_columns = get_feature_names(fixlen_feature_columns)    \n",
    "    \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Final_Train[lgbm_train_columns],Final_Train['TOTAL_RATE'] ,test_size=0.2, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_wrapper = LGBMRegressor(n_estimators=400)\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='mae', eval_set=evals, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgbm_wrapper.predict(X_test)\n",
    "mean_squared_error(pred,y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "fm.get_fontconfig_fonts()\n",
    "font_location = '/workspace/RS/Gooddoc/NanumGothic.otf'\n",
    "font_name = fm.FontProperties(fname=font_location).get_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family=font_name)\n",
    "print(plt.rcParams['font.family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(lgbm_wrapper, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=10)\n",
    "\n",
    "def objective(trial):\n",
    "    dtrain = Dataset(X_train, label=y_train)\n",
    "    dtest = Dataset(X_test, label=y_test)\n",
    "\n",
    "    param = {\n",
    "        'objective': 'regression', # 회귀\n",
    "        'verbose': -1,\n",
    "        'metric': 'rmse', \n",
    "        'max_depth': trial.suggest_int('max_depth',3, 30),\n",
    "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**param)\n",
    "    lgb_model = model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0, early_stopping_rounds=25)\n",
    "    mse = mean_squared_error(y_test, lgb_model.predict(X_test))\n",
    "    return mse\n",
    "        \n",
    "study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study_lgb.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgb_model = LGBMRegressor(**trial_params)\n",
    "final_lgb_model.fit(X_train, y_train)\n",
    "final_lgb_pred = final_lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgb_model = lgb.LGBMRegressor(**trial_params)\n",
    "final_lgb_model.fit(train_X, train_y)\n",
    "final_lgb_pred = final_lgb_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_lgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

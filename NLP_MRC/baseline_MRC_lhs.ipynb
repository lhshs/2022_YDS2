{"cells":[{"cell_type":"markdown","metadata":{"id":"74d0cf9f-03f5-4446-be51-a96049fa0121"},"source":["# 문서 검색 효율화를 위한 기계독해\n","- 1차 모의경진대회(22.11.14 ~ 22.11.25)\n","- 자연어 기계독해(Machine Reading Comprehension) 과제"],"id":"74d0cf9f-03f5-4446-be51-a96049fa0121"},{"cell_type":"markdown","metadata":{"id":"NWNHSk-pSskv"},"source":["## 데이터 구조\n","\n","```\n","$ MRC/\n","├── DATA/\n","│   ├── train.json\n","│   ├── test.json\n","│   └── sample_submission.csv\n","├── prediction.csv (코드 실행 후 생성)\n","├── results/ (코드 실행 후 생성)\n","```"],"id":"NWNHSk-pSskv"},{"cell_type":"markdown","metadata":{"id":"xidLcL3yK3wm"},"source":["#0. 사전 준비"],"id":"xidLcL3yK3wm"},{"cell_type":"markdown","metadata":{"id":"qPmVS-p6K992"},"source":["##0.1 구글 드라이브 마운트"],"id":"qPmVS-p6K992"},{"cell_type":"code","execution_count":1,"metadata":{"id":"VHgjTjglFXf8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668597283840,"user_tz":-540,"elapsed":27108,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"f1d93a04-a014-4f09-c18b-c95567061187"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 Colaboratory 를 사용하기 위해 구글 계정으로 로그인합니다. \n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"VHgjTjglFXf8"},{"cell_type":"markdown","metadata":{"id":"bYuiNxj7LQgH"},"source":["##0.2 라이브러리 설치"],"id":"bYuiNxj7LQgH"},{"cell_type":"code","execution_count":2,"metadata":{"id":"OchkeVlBLK_8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668597293524,"user_tz":-540,"elapsed":9689,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"778abeea-7df3-400d-da85-82cc310a6c14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 25.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 60.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 72.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"]}],"source":["!pip install transformers"],"id":"OchkeVlBLK_8"},{"cell_type":"markdown","metadata":{"id":"420e527f-ff52-4bb3-a260-565fe2f91e2d"},"source":["##1. 라이브러리 불러오기"],"id":"420e527f-ff52-4bb3-a260-565fe2f91e2d"},{"cell_type":"code","execution_count":3,"metadata":{"id":"5b80416a-1082-4ae9-8057-18eb163dfc15","executionInfo":{"status":"ok","timestamp":1668597299127,"user_tz":-540,"elapsed":5608,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["import os\n","import sys\n","import csv\n","import copy\n","import json\n","import random\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","from datetime import datetime, timezone, timedelta\n","\n","from transformers import ElectraTokenizerFast\n","from transformers import ElectraForQuestionAnswering\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"id":"5b80416a-1082-4ae9-8057-18eb163dfc15"},{"cell_type":"markdown","metadata":{"id":"e031838b-d5ad-4887-ae60-07ff98a71a0a"},"source":["##2. 하이퍼파라미터 및 기타 인자 설정"],"id":"e031838b-d5ad-4887-ae60-07ff98a71a0a"},{"cell_type":"markdown","metadata":{"id":"9e7be91e-9928-453e-8aeb-a6af032b7dcb"},"source":["###2.1 데이터 경로"],"id":"9e7be91e-9928-453e-8aeb-a6af032b7dcb"},{"cell_type":"code","execution_count":65,"metadata":{"id":"2bee580a-4c2a-42b4-9f1d-78b8d5e63981","executionInfo":{"status":"ok","timestamp":1668601292834,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["PROJECT_DIR = '/content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC' # 프로젝트 디렉토리 설정\n","DATA_DIR= '/content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/DATA' # 데이터 디렉토리 설정"],"id":"2bee580a-4c2a-42b4-9f1d-78b8d5e63981"},{"cell_type":"markdown","metadata":{"id":"f923389a-631d-4a17-8542-382fa0d6e68b"},"source":["###2.2 시드 설정"],"id":"f923389a-631d-4a17-8542-382fa0d6e68b"},{"cell_type":"code","execution_count":66,"metadata":{"id":"97cb0fc4-cce7-45b7-876d-84d00a32f68c","executionInfo":{"status":"ok","timestamp":1668601295545,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["# 난수 생성기가 항상 일정한 값을 출력하게 하기 위해 seed 고정\n","RANDOM_SEED = 42\n","\n","torch.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)"],"id":"97cb0fc4-cce7-45b7-876d-84d00a32f68c"},{"cell_type":"markdown","metadata":{"id":"88051bcc-8a4e-4552-af85-4fb62d9e2658"},"source":["###2.3 하이퍼파라미터 설정"],"id":"88051bcc-8a4e-4552-af85-4fb62d9e2658"},{"cell_type":"code","execution_count":67,"metadata":{"id":"42d42463-8bf9-4ea7-a42a-72f763adb515","executionInfo":{"status":"ok","timestamp":1668601297938,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["LEARNING_RATE = 3.0e-4     # 학습률(learning rate)은 경사하강법(gradient descent)을 통해 내리막길을 내려갈 때의 보폭\n","BATCH_SIZE = 8     # 배치(batch)는 모델의 가중치(weights)를 업데이트하는 학습 데이터의 단위. 여기서는 16개를 학습할 때마다 모델의 가중치(weights)를 업데이트한다는 것\n","PIN_MEMORY = True\n","NUM_WORKERS = 0\n","EPOCHS = 2     # 에폭은 전체 학습 데이터를 학습에 사용하는 횟수. 주어진 학습 데이터를 여러번 학습할 수 있음\n","DROP_LAST = False\n","EARLY_STOPPING_MODE = min\n","EARLY_STOPPING_PATIENCE = 10\n","EARLY_STOPPING_TARGET = 'val_loss'     # validation set의 loss를 기준으로 early_stopping 여부를 결정할 것\n","LOGGING_INTERVAL = 200"],"id":"42d42463-8bf9-4ea7-a42a-72f763adb515"},{"cell_type":"markdown","metadata":{"id":"01a3191b-b482-4f9f-85e0-be96c5f09824"},"source":["###2.4 디바이스 설정"],"id":"01a3191b-b482-4f9f-85e0-be96c5f09824"},{"cell_type":"code","execution_count":68,"metadata":{"id":"626e7afa-2a56-4094-9e75-cfb3bec09606","executionInfo":{"status":"ok","timestamp":1668601300955,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"626e7afa-2a56-4094-9e75-cfb3bec09606"},{"cell_type":"code","source":["# !nvidia-smi\n","print('Device:', device)\n","print('Current cuda device:', torch.cuda.current_device())\n","print('Count of using GPUs:', torch.cuda.device_count())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQUlqJJbI0Xi","executionInfo":{"status":"ok","timestamp":1668601301695,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"dd539ed4-6130-444b-f212-0c2ced6543bc"},"id":"qQUlqJJbI0Xi","execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Current cuda device: 0\n","Count of using GPUs: 1\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dnmi8biFJpKm","executionInfo":{"status":"ok","timestamp":1668601302229,"user_tz":-540,"elapsed":6,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"2ece3dea-e3f1-4801-a601-9a4608a8d29b"},"id":"Dnmi8biFJpKm","execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Nov 16 12:21:41 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P0    26W /  70W |   6946MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"863de192-3f18-421f-a06f-a5964bdbeb87"},"source":["##3. Dataset 정의"],"id":"863de192-3f18-421f-a06f-a5964bdbeb87"},{"cell_type":"code","execution_count":71,"metadata":{"id":"2c5fa64b-a355-43d2-95dc-94bb8605cc15","executionInfo":{"status":"ok","timestamp":1668601306349,"user_tz":-540,"elapsed":3,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class QADataset(Dataset):     # 데이터를 input으로 변환해주는 Dataset 클래스를 상속하여, QA(Question Answering) 과제에 맞게 커스터마이징한다\n","    \n","    def __init__ (self, data_dir: str, tokenizer, max_seq_len: int, mode = 'train'):     # Dataset 클래스는 기본적으로 __init__, __len__, __getitem__를 정의해 주어야 한다\n","        self.mode = mode\n","        self.data = json.load(open(data_dir, 'r', encoding='utf8'))\n","        \n","        self.tokenizer = tokenizer\n","        self.max_seq_len = max_seq_len\n","        \n","        if mode == 'test':\n","            self.encodings, self.question_ids = self.preprocess()\n","        else:\n","            self.encodings, self.answers = self.preprocess()\n","        \n","    def __len__(self):     # index를 통해 input을 순차적으로 읽어오기 위해서는 데이터의 길이가 먼저 확인되어야 한다. __len__ 함수는 input의 길이를 반환해주는 함수\n","        return len(self.encodings.input_ids)\n","\n","    def __getitem__(self, index: int):     # input의 길이가 확인되면 index를 통해 데이터를 불러올 수 있다. __getitem__ 함수는 index에 해당하는 input 데이터를 반환해주는 함수\n","        return {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n","\n","    \n","    def preprocess(self):\n","        contexts, questions, answers, question_ids = self.read_squad()     # SQuAD(Stanford Question Answering Dataset) 형식의 데이터에서 contexts, questions, answers, question_ids를 읽어오는 함수\n","        if self.mode == 'test':\n","            encodings = self.tokenizer(contexts, questions, truncation=True, max_length = self.max_seq_len, padding=True)\n","            return encodings, question_ids\n","        else: # train or val\n","            self.add_end_idx(answers, contexts)     # train.json에는 질문에 대한 답이 context 내에서 시작되는 index인 'answer_srart'만 있기 때문에, 추가로 'answer_end'를 찾아주는 함수\n","            encodings = self.tokenizer(contexts, questions, truncation=True, max_length = self.max_seq_len, padding=True)\n","            self.add_token_positions(encodings, answers)\n","        \n","            return encodings, answers\n","        \n","    \n","    def read_squad(self):     # SQuAD(Stanford Question Answering Dataset) 형식의 데이터에서 contexts, questions, answers, question_ids를 읽어오는 함수\n","        contexts = []\n","        questions = []\n","        question_ids = []\n","        answers = []\n","        \n","        # train - val split\n","        if self.mode == 'train':\n","            self.data['data'] = self.data['data'][:-1*int(len(self.data['data'])*0.1)]\n","        elif self.mode == 'val':\n","            self.data['data'] = self.data['data'][-1*int(len(self.data['data'])*0.1):]\n","        \n","        \n","        till = len(self.data['data'])\n","        \n","\n","        for group in self.data['data'][:till]:\n","            for passage in group['paragraphs']:\n","                context = passage['context']\n","                for qa in passage['qas']:\n","                    question = qa['question']\n","                    if self.mode == 'test':\n","                        contexts.append(context)\n","                        questions.append(question)\n","                        question_ids.append(qa['question_id'])\n","                    else: # train or val\n","                        for ans in qa['answers']:\n","                            contexts.append(context)\n","                            questions.append(question)\n","\n","                            if qa['is_impossible']:\n","                                answers.append({'text':'','answer_start':-1})\n","                            else:\n","                                answers.append(ans)\n","                \n","        # return formatted data lists\n","        return contexts, questions, answers, question_ids\n","    \n","    \n","    def add_end_idx(self, answers, contexts):     # train.json에는 질문에 대한 답이 context 내에서 시작되는 index인 'answer_srart'만 있기 때문에, 추가로 'answer_end'를 찾아주는 함수\n","        for answer, context in zip(answers, contexts):\n","            gold_text = answer['text']\n","            start_idx = answer['answer_start']\n","            end_idx = start_idx + len(gold_text)\n","\n","            # in case the indices are off 1-2 idxs\n","            if context[start_idx:end_idx] == gold_text:\n","                answer['answer_end'] = end_idx\n","            else:\n","                for n in [1, 2]:\n","                    if context[start_idx-n:end_idx-n] == gold_text:\n","                        answer['answer_start'] = start_idx - n\n","                        answer['answer_end'] = end_idx - n\n","                    elif context[start_idx+n:end_idx+n] == gold_text:\n","                        answer['answer_start'] = start_idx + n\n","                        answer['answer_end'] = end_idx + n\n","                        \n","\n","    def add_token_positions(self, encodings, answers):\n","        # should use Fast tokenizer\n","        start_positions = []\n","        end_positions = []\n","        for i in range(len(answers)):\n","            if answers[i]['answer_start'] == -1:\n","                # set [CLS] token as answer if is_impossible\n","                start_positions.append(0)\n","                end_positions.append(1)\n","            else:\n","                start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","\n","                assert 'answer_end' in answers[i].keys(), f'no answer_end at {i}'\n","                end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n","\n","            # answer passage truncated\n","            if start_positions[-1] is None:\n","                start_positions[-1] = tokenizer.model_max_length                \n","            # end position cannot be found, shift until found\n","            shift = 1\n","            while end_positions[-1] is None:\n","                end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n","                shift += 1\n","                \n","        # char-based -> token based\n","        encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"],"id":"2c5fa64b-a355-43d2-95dc-94bb8605cc15"},{"cell_type":"markdown","metadata":{"id":"c5842a98-c4d9-477c-bfbb-db93a1bdca32"},"source":["##4. 모델 정의"],"id":"c5842a98-c4d9-477c-bfbb-db93a1bdca32"},{"cell_type":"code","execution_count":72,"metadata":{"id":"69904ef0-ec62-4eb2-8540-9f44a112fc1c","executionInfo":{"status":"ok","timestamp":1668601310399,"user_tz":-540,"elapsed":3,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class electra(nn.Module):     # pytorch의 모든 neural network 모델들은 torch.nn.Module 클래스를 상속해야 한다. 기본적으로 __init__()과 forward 함수가 override(재정의)되어야 하며, forward 함수는 모델의 계산을 실행하는 것을 뜻한다.\n","\n","    def __init__(self, pretrained, **kwargs):\n","        super(electra, self).__init__()\n","\n","        self.model = ElectraForQuestionAnswering.from_pretrained(pretrained)     # Hugging Face에서 pretrain된 모델을 가져와서 model 변수에 저장한다.\n","        \n","\n","    def forward(self, input_ids, attention_mask, start_positions=None, end_positions=None):\n","        \n","        outputs = self.model(input_ids = input_ids, \n","                             attention_mask = attention_mask,\n","                             start_positions = start_positions,\n","                             end_positions = end_positions)\n","        \n","        return outputs"],"id":"69904ef0-ec62-4eb2-8540-9f44a112fc1c"},{"cell_type":"markdown","metadata":{"id":"9615d17d-1f80-45e9-8583-e4b3f3a84f44"},"source":["##5. Utils 정의\n","###5.1 EarlyStopper"],"id":"9615d17d-1f80-45e9-8583-e4b3f3a84f44"},{"cell_type":"code","execution_count":73,"metadata":{"id":"e9ea7473-7a39-48d9-a0c7-5ef197c99547","executionInfo":{"status":"ok","timestamp":1668601310890,"user_tz":-540,"elapsed":1,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class EarlyStopper():     # 일정 기간 모델 성능에 개선이 없으면, 학습을 중단하는 기능\n","\n","    def __init__(self, patience: int, mode:str)-> None:\n","        self.patience = patience\n","        self.mode = mode\n","\n","        # Initiate\n","        self.patience_counter = 0\n","        self.stop = False\n","        self.best_loss = np.inf\n","\n","        print(f\"Initiated early stopper, mode: {self.mode}, best score: {self.best_loss}, patience: {self.patience}\")\n","\n","        \n","    def check_early_stopping(self, loss: float)-> None:\n","        loss = -loss if self.mode == 'max' else loss  # get max value if mode set to max\n","\n","        if loss > self.best_loss:\n","            # got worse score\n","            self.patience_counter += 1\n","\n","            print(f\"Early stopper, counter {self.patience_counter}/{self.patience}, best:{abs(self.best_loss)} -> now:{abs(loss)}\")\n","            \n","            if self.patience_counter == self.patience:\n","                print(f\"Early stopper, stop\")\n","                self.stop = True  # end\n","\n","        elif loss <= self.best_loss:\n","            # got better score\n","            self.patience_counter = 0\n","            \n","            print(f\"Early stopper, counter {self.patience_counter}/{self.patience}, best:{abs(self.best_loss)} -> now:{abs(loss)}\")\n","            print(f\"Set counter as {self.patience_counter}\")\n","            print(f\"Update best score as {abs(loss)}\")\n","            \n","            self.best_loss = loss\n","            \n","        else:\n","            print('debug')"],"id":"e9ea7473-7a39-48d9-a0c7-5ef197c99547"},{"cell_type":"markdown","metadata":{"id":"c53b4cda-5607-4a52-ad4b-a0ae33940004"},"source":["###5.2 Trainer"],"id":"c53b4cda-5607-4a52-ad4b-a0ae33940004"},{"cell_type":"code","execution_count":74,"metadata":{"id":"636e914f-d8cb-47b4-8fa0-3f6918653ae0","executionInfo":{"status":"ok","timestamp":1668601312758,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class Trainer():     # 학습을 위한 Trainer 클래스 정의\n","\n","    def __init__(self,\n","                 model,\n","                 optimizer,\n","                 loss,\n","                 metrics,\n","                 device,\n","                 tokenizer,\n","                 interval=100):\n","        \n","        self.model = model\n","        self.optimizer = optimizer\n","        self.loss = loss\n","        self.metrics = metrics\n","        self.device = device\n","        self.interval = interval\n","        self.tokenizer = tokenizer\n","\n","        # History\n","        self.loss_sum = 0  # Epoch loss sum\n","        self.loss_mean = 0 # Epoch loss mean\n","        self.y = list()\n","        self.y_preds = list()\n","        self.score_dict = dict()  # metric score\n","        self.elapsed_time = 0\n","        \n","\n","    def train(self, mode, dataloader, tokenizer, epoch_index=0):\n","        \n","        start_timestamp = time()\n","        self.model.train() if mode == 'train' else self.model.eval()     # 모델을 train(eval) mode로 전환.  train(eval) mode에서는 dropout, batchnorm이 적용된다(적용되지 않는다)\n"," \n","        for batch_index, batch in enumerate(tqdm(dataloader, leave=True)):\n","            \n","            self.optimizer.zero_grad()     # 파라미터 업데이트는 batch 단위로 이루어지고, 매 batch마다 이전 스텝에서 계산된 gradient를 초기화해주어야 함\n","            # pull all the tensor batches required for training\n","            input_ids = batch['input_ids'].to(self.device)\n","            attention_mask = batch['attention_mask'].to(self.device)\n","            start_positions = batch['start_positions'].to(self.device)\n","            end_positions = batch['end_positions'].to(self.device)\n","            \n","            # train model on batch and return outputs (incl. loss)\n","            # Inference\n","            outputs = self.model(input_ids, attention_mask=attention_mask,\n","                            start_positions=start_positions,\n","                            end_positions=end_positions)\n","            \n","            loss = outputs.loss\n","            start_score = outputs.start_logits\n","            end_score = outputs.end_logits\n","            \n","            \n","            start_idx = torch.argmax(start_score, dim=1).cpu().tolist()\n","            end_idx = torch.argmax(end_score, dim=1).cpu().tolist()\n","            \n","            # Update\n","            if mode == 'train':\n","                loss.backward()     # backpropagation\n","                self.optimizer.step()     # 파라미터 업데이트\n","                \n","            elif mode in ['val', 'test']:\n","                pass\n","            \n","            # History\n","            self.loss_sum += loss.item()\n","            \n","            # create answer; list of strings\n","            for i in range(len(input_ids)):\n","                if start_idx[i] > end_idx[i]:\n","                    output = ''\n","                \n","                self.y_preds.append(self.tokenizer.decode(input_ids[i][start_idx[i]:end_idx[i]]))\n","                self.y.append(self.tokenizer.decode(input_ids[i][start_positions[i]:end_positions[i]]))\n","\n","\n","            # Logging\n","            if batch_index % self.interval == 0:\n","                print(f\"batch: {batch_index}/{len(dataloader)} loss: {loss.item()}\")\n","                \n","        # Epoch history\n","        self.loss_mean = self.loss_sum / len(dataloader)  # Epoch loss mean\n","\n","        # Metric\n","        score = self.metrics(self.y, self.y_preds)\n","        self.score_dict['metric_name'] = score\n","\n","        # Elapsed time\n","        end_timestamp = time()\n","        self.elapsed_time = end_timestamp - start_timestamp\n","\n","    def clear_history(self):\n","        self.loss_sum = 0\n","        self.loss_mean = 0\n","        self.y_preds = list()\n","        self.y = list()\n","        self.score_dict = dict()\n","        self.elapsed_time = 0"],"id":"636e914f-d8cb-47b4-8fa0-3f6918653ae0"},{"cell_type":"markdown","metadata":{"id":"1f530fc6-25e7-4b9c-9431-7a5ea267c348"},"source":["###5.3 Recorder"],"id":"1f530fc6-25e7-4b9c-9431-7a5ea267c348"},{"cell_type":"code","execution_count":75,"metadata":{"id":"89b61d3c-858b-4213-a1c1-8f32bed3698a","executionInfo":{"status":"ok","timestamp":1668601316987,"user_tz":-540,"elapsed":470,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class Recorder():\n","\n","    def __init__(self,\n","                 record_dir: str,\n","                 model: object,\n","                 optimizer: object):\n","        \n","        self.record_dir = record_dir\n","        self.record_filepath = os.path.join(self.record_dir, 'record.csv')\n","        self.weight_path = os.path.join(record_dir, 'model.pt')\n","\n","        self.model = model\n","        self.optimizer = optimizer\n","\n","        \n","    def set_model(self, model: 'model'):\n","        self.model = model\n","\n","\n","    def add_row(self, row_dict: dict):\n","\n","        fieldnames = list(row_dict.keys())\n","\n","        with open(self.record_filepath, newline='', mode='a') as f:\n","            writer = csv.DictWriter(f, fieldnames=fieldnames)\n","\n","            if f.tell() == 0:\n","                writer.writeheader()\n","\n","            writer.writerow(row_dict)\n","            print(f\"Write row {row_dict['epoch_index']}\")\n","\n","            \n","    def save_weight(self, epoch: int)-> None:\n","        check_point = {\n","            'epoch': epoch + 1,\n","            'model': self.model.state_dict(),\n","            'optimizer': self.optimizer.state_dict(),\n","        }\n","        \n","        torch.save(check_point, self.weight_path)\n","        print(f\"Recorder, epoch {epoch} Model saved: {self.weight_path}\")"],"id":"89b61d3c-858b-4213-a1c1-8f32bed3698a"},{"cell_type":"markdown","metadata":{"id":"66c1c276-2264-43b9-aa62-44cfd81ee395"},"source":["##6. 모델 학습"],"id":"66c1c276-2264-43b9-aa62-44cfd81ee395"},{"cell_type":"markdown","metadata":{"id":"aa925da6-d006-4fb9-a763-021ffe9bc8e4"},"source":["###6.1 모델과 기타 utils 설정"],"id":"aa925da6-d006-4fb9-a763-021ffe9bc8e4"},{"cell_type":"code","execution_count":76,"metadata":{"id":"714f8a41-c14f-4fc5-84ae-b04f0452a952","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668601321415,"user_tz":-540,"elapsed":1982,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"e1d8c6d4-f965-4d35-861b-b30479aea5d1"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Initiated early stopper, mode: <built-in function min>, best score: inf, patience: 10\n"]}],"source":["# Load model\n","model = electra(pretrained='monologg/koelectra-small-v3-discriminator').to(device)\n","\n","# Set optimizer, loss function, metric function\n","optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","loss = F.cross_entropy\n","metrics = accuracy_score\n","\n","# Set tokenizer\n","tokenizer = ElectraTokenizerFast.from_pretrained('monologg/koelectra-small-v3-discriminator')\n","\n","# Set Trainer\n","trainer = Trainer(model=model,\n","                  optimizer=optimizer,\n","                  loss=loss,\n","                  metrics=metrics,\n","                  device=device,\n","                  tokenizer=tokenizer,\n","                  interval=LOGGING_INTERVAL)\n","\n","# Set earlystopper\n","early_stopper = EarlyStopper(patience=EARLY_STOPPING_PATIENCE,\n","                            mode=min)\n","\n","# Set train serial\n","kst = timezone(timedelta(hours=9))\n","train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n","\n","\n","# Set recorder \n","RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n","os.makedirs(RECORDER_DIR, exist_ok=True)\n","\n","recorder = Recorder(record_dir=RECORDER_DIR,\n","                    model=model,\n","                    optimizer=optimizer)"],"id":"714f8a41-c14f-4fc5-84ae-b04f0452a952"},{"cell_type":"markdown","metadata":{"id":"c715ceb0-4555-431a-ab9d-8f6f99dd783f"},"source":["###6.2 Dataset & Dataloader 설정"],"id":"c715ceb0-4555-431a-ab9d-8f6f99dd783f"},{"cell_type":"code","execution_count":77,"metadata":{"id":"d504be1e-67c8-4de5-b8d0-225ac0b8fd65","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668601377916,"user_tz":-540,"elapsed":15786,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"6105f6a1-b1d2-40b5-82b7-7102471c24aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Load data, train:25262 val:2762\n"]}],"source":["# torch.utils.data.Dataset : 데이터를 input으로 변환\n","train_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'train')\n","val_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'val')\n","\n","# torch.utils.data.DataLoader : input을 배치 단위로 리턴해주는 기능\n","train_dataloader = DataLoader(dataset=train_dataset,\n","                              batch_size=BATCH_SIZE,\n","                              num_workers=NUM_WORKERS, \n","                              shuffle=True,\n","                              pin_memory=PIN_MEMORY,\n","                              drop_last=DROP_LAST)\n","\n","val_dataloader = DataLoader(dataset=val_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            num_workers=NUM_WORKERS, \n","                            shuffle=False,\n","                            pin_memory=PIN_MEMORY,\n","                            drop_last=DROP_LAST)\n","\n","print(f\"Load data, train:{len(train_dataset)} val:{len(val_dataset)}\")"],"id":"d504be1e-67c8-4de5-b8d0-225ac0b8fd65"},{"cell_type":"markdown","metadata":{"id":"3e685537-7c8b-439c-8258-00c658bb360a"},"source":["###6.3 Epoch 단위 학습 진행"],"id":"3e685537-7c8b-439c-8258-00c658bb360a"},{"cell_type":"code","execution_count":78,"metadata":{"id":"661bf57c-20d2-4e14-bffb-e7db7eb85f78","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668602239872,"user_tz":-540,"elapsed":859238,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"994e64bf-abe6-4554-b12b-71c3da577e2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train 0/2\n","--Train 0/2\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/3158 [00:00<15:26,  3.41it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/3158 loss: 6.138935089111328\n"]},{"output_type":"stream","name":"stderr","text":["  6%|▋         | 202/3158 [00:25<06:19,  7.78it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/3158 loss: 13.719535827636719\n"]},{"output_type":"stream","name":"stderr","text":[" 13%|█▎        | 402/3158 [00:51<05:50,  7.85it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 400/3158 loss: 13.410654067993164\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 602/3158 [01:17<05:26,  7.84it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 600/3158 loss: 60.60235595703125\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 802/3158 [01:43<05:12,  7.54it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 800/3158 loss: 43.75200271606445\n"]},{"output_type":"stream","name":"stderr","text":[" 32%|███▏      | 1002/3158 [02:09<04:40,  7.68it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1000/3158 loss: 6.113137245178223\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 1202/3158 [02:35<04:16,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1200/3158 loss: 5.975471496582031\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 1402/3158 [03:01<03:51,  7.59it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1400/3158 loss: 6.062824249267578\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 1602/3158 [03:28<03:25,  7.58it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1600/3158 loss: 6.225635051727295\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 1802/3158 [03:54<02:58,  7.59it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1800/3158 loss: 6.123079299926758\n"]},{"output_type":"stream","name":"stderr","text":[" 63%|██████▎   | 2002/3158 [04:20<02:31,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2000/3158 loss: 70.16072845458984\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|██████▉   | 2202/3158 [04:46<02:06,  7.55it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2200/3158 loss: 8.21078109741211\n"]},{"output_type":"stream","name":"stderr","text":[" 76%|███████▌  | 2402/3158 [05:12<01:39,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2400/3158 loss: 6.1716766357421875\n"]},{"output_type":"stream","name":"stderr","text":[" 82%|████████▏ | 2602/3158 [05:39<01:12,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2600/3158 loss: 6.113694190979004\n"]},{"output_type":"stream","name":"stderr","text":[" 89%|████████▊ | 2802/3158 [06:05<00:46,  7.61it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2800/3158 loss: 6.20697021484375\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 3002/3158 [06:31<00:20,  7.56it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3000/3158 loss: 6.14498233795166\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3158/3158 [06:51<00:00,  7.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val 0/2\n","--Val 0/2\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 3/346 [00:00<00:14, 23.72it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/346 loss: 6.077642440795898\n"]},{"output_type":"stream","name":"stderr","text":[" 59%|█████▉    | 204/346 [00:08<00:06, 22.86it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/346 loss: 6.077642440795898\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 346/346 [00:15<00:00, 22.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Write row 0\n","Early stopper, counter 0/10, best:inf -> now:6.077642440795898\n","Set counter as 0\n","Update best score as 6.077642440795898\n","Recorder, epoch 0 Model saved: /content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/results/train/20221116_212201/model.pt\n","Train 1/2\n","--Train 1/2\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/3158 [00:00<06:56,  7.57it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/3158 loss: 6.194218635559082\n"]},{"output_type":"stream","name":"stderr","text":["  6%|▋         | 202/3158 [00:26<06:27,  7.63it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/3158 loss: 6.1278276443481445\n"]},{"output_type":"stream","name":"stderr","text":[" 13%|█▎        | 402/3158 [00:52<06:02,  7.60it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 400/3158 loss: 99.34613800048828\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 602/3158 [01:18<05:32,  7.69it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 600/3158 loss: 23.010454177856445\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 802/3158 [01:45<05:09,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 800/3158 loss: 6.150129795074463\n"]},{"output_type":"stream","name":"stderr","text":[" 32%|███▏      | 1002/3158 [02:11<04:42,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1000/3158 loss: 5.9736504554748535\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 1202/3158 [02:37<04:16,  7.63it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1200/3158 loss: 6.057809829711914\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 1402/3158 [03:04<03:52,  7.55it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1400/3158 loss: 6.057488918304443\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 1602/3158 [03:30<03:22,  7.67it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1600/3158 loss: 6.3014302253723145\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 1802/3158 [03:56<02:59,  7.57it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1800/3158 loss: 6.249115467071533\n"]},{"output_type":"stream","name":"stderr","text":[" 63%|██████▎   | 2002/3158 [04:22<02:31,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2000/3158 loss: 6.004032135009766\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|██████▉   | 2202/3158 [04:49<02:04,  7.65it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2200/3158 loss: 5.922719955444336\n"]},{"output_type":"stream","name":"stderr","text":[" 76%|███████▌  | 2402/3158 [05:15<01:38,  7.69it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2400/3158 loss: 146.30307006835938\n"]},{"output_type":"stream","name":"stderr","text":[" 82%|████████▏ | 2602/3158 [05:41<01:13,  7.57it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2600/3158 loss: 32.78034210205078\n"]},{"output_type":"stream","name":"stderr","text":[" 89%|████████▊ | 2802/3158 [06:07<00:47,  7.52it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2800/3158 loss: 6.180456161499023\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 3002/3158 [06:33<00:20,  7.68it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3000/3158 loss: 6.078419208526611\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3158/3158 [06:54<00:00,  7.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val 1/2\n","--Val 1/2\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 3/346 [00:00<00:14, 23.97it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/346 loss: 6.077642440795898\n"]},{"output_type":"stream","name":"stderr","text":[" 59%|█████▉    | 204/346 [00:08<00:06, 22.87it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/346 loss: 6.077642440795898\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 346/346 [00:15<00:00, 22.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Write row 1\n","Early stopper, counter 0/10, best:6.077642440795898 -> now:6.077642440795898\n","Set counter as 0\n","Update best score as 6.077642440795898\n","Recorder, epoch 1 Model saved: /content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/results/train/20221116_212201/model.pt\n"]}],"source":["# Train\n","for epoch_index in range(EPOCHS):\n","\n","    # Set Recorder row\n","    row_dict = dict()\n","    row_dict['epoch_index'] = epoch_index\n","    row_dict['train_serial'] = train_serial\n","\n","    \"\"\"\n","    Train\n","    \"\"\"\n","    print(f\"Train {epoch_index}/{EPOCHS}\")\n","    print(f\"--Train {epoch_index}/{EPOCHS}\")\n","    trainer.train(dataloader=train_dataloader, epoch_index=epoch_index, tokenizer=tokenizer, mode='train')\n","\n","    row_dict['train_loss'] = trainer.loss_mean\n","    row_dict['train_elapsed_time'] = trainer.elapsed_time \n","\n","    for metric_str, score in trainer.score_dict.items():\n","        row_dict[f\"train_{metric_str}\"] = score\n","    trainer.clear_history()\n","\n","    \"\"\"\n","    Validation\n","    \"\"\"\n","    print(f\"Val {epoch_index}/{EPOCHS}\")\n","    print(f\"--Val {epoch_index}/{EPOCHS}\")\n","    trainer.train(dataloader=val_dataloader, epoch_index=epoch_index, tokenizer=tokenizer, mode='val')\n","\n","    row_dict['val_loss'] = trainer.loss_mean\n","    row_dict['val_elapsed_time'] = trainer.elapsed_time \n","\n","    for metric_str, score in trainer.score_dict.items():\n","        row_dict[f\"val_{metric_str}\"] = score\n","    trainer.clear_history()\n","\n","    \"\"\"\n","    Record\n","    \"\"\"\n","    recorder.add_row(row_dict)\n","\n","    \"\"\"\n","    Early stopper\n","    \"\"\"\n","    early_stopping_target = EARLY_STOPPING_TARGET\n","    early_stopper.check_early_stopping(loss=row_dict[early_stopping_target])\n","\n","    if early_stopper.patience_counter == 0:\n","        recorder.save_weight(epoch=epoch_index)\n","        best_row_dict = copy.deepcopy(row_dict)\n","\n","    if early_stopper.stop == True:\n","        print(f\"Early stopped, counter {early_stopper.patience_counter}/{EARLY_STOPPING_PATIENCE}\")\n","\n","        break"],"id":"661bf57c-20d2-4e14-bffb-e7db7eb85f78"},{"cell_type":"markdown","metadata":{"id":"ed9d2987-378c-45df-84bf-ee4589ac61d4"},"source":["##7. 추론"],"id":"ed9d2987-378c-45df-84bf-ee4589ac61d4"},{"cell_type":"markdown","metadata":{"id":"0dee7dae-24d0-4cf3-b641-c3938ceda233"},"source":["###7.1 테스트 Dataset & Dataloader 설정"],"id":"0dee7dae-24d0-4cf3-b641-c3938ceda233"},{"cell_type":"code","execution_count":83,"metadata":{"id":"a67fcd63-de84-41fe-a620-8771d799722b","executionInfo":{"status":"ok","timestamp":1668602263087,"user_tz":-540,"elapsed":1460,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["# Load data\n","test_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'test.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'test')\n","\n","question_ids = test_dataset.question_ids\n","\n","test_dataloader = DataLoader(dataset=test_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            num_workers=NUM_WORKERS, \n","                            shuffle=False,\n","                            pin_memory=PIN_MEMORY,\n","                            drop_last=DROP_LAST)"],"id":"a67fcd63-de84-41fe-a620-8771d799722b"},{"cell_type":"markdown","metadata":{"id":"733f8fc5-d1e8-4027-b8c7-ed87ec409246"},"source":["###7.2 모델 로드"],"id":"733f8fc5-d1e8-4027-b8c7-ed87ec409246"},{"cell_type":"code","execution_count":84,"metadata":{"id":"86cc6eeb-6f7c-4765-9478-83cb9ce62954","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668602264841,"user_tz":-540,"elapsed":1023,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"282146b8-79c0-4e12-df1f-f4656934c925"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":84}],"source":["# Load model\n","\n","model = electra(pretrained='monologg/koelectra-small-v3-discriminator').to(device)\n","\n","checkpoint = torch.load(os.path.join(RECORDER_DIR, 'model.pt'))\n","\n","model.load_state_dict(checkpoint['model'])"],"id":"86cc6eeb-6f7c-4765-9478-83cb9ce62954"},{"cell_type":"code","source":["RECORDER_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"_h2ZKq5Tctw_","executionInfo":{"status":"ok","timestamp":1668602324703,"user_tz":-540,"elapsed":528,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"ab349307-4dc9-4df8-e217-ab5ffa7be9ed"},"id":"_h2ZKq5Tctw_","execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/results/train/20221116_212201'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"ea6e2ce2-c11a-42b0-baaa-107251e077a3"},"source":["###7.3 추론 진행"],"id":"ea6e2ce2-c11a-42b0-baaa-107251e077a3"},{"cell_type":"code","execution_count":88,"metadata":{"id":"6876e75d-f3ba-4007-a548-062d4b1ce681","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668602374760,"user_tz":-540,"elapsed":8031,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"df11e2f2-60ad-438d-92ba-5d772b749e23"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 204/204 [00:08<00:00, 24.83it/s]\n"]}],"source":["model.eval()     # 모델을 eval mode로 전환. train mode와 달리 eval mode에서는 dropout, batchnorm이 적용되지 않는다\n","\n","pred_df = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))\n","\n","for batch_index, batch in enumerate(tqdm(test_dataloader, leave=True)):\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","\n","    # Inference\n","    outputs = model(input_ids, attention_mask=attention_mask)\n","\n","    start_score = outputs.start_logits\n","    end_score = outputs.end_logits\n","\n","    start_idx = torch.argmax(start_score, dim=1).cpu().tolist()\n","    end_idx = torch.argmax(end_score, dim=1).cpu().tolist()\n","\n","    y_pred = []\n","    for i in range(len(input_ids)):\n","        if start_idx[i] > end_idx[i]:\n","            output = ''\n","\n","        ans_txt = tokenizer.decode(input_ids[i][start_idx[i]:end_idx[i]]).replace('#','')\n","\n","        if ans_txt == '[CLS]':\n","            ans_txt == ''\n","\n","        y_pred.append(ans_txt)\n","\n","\n","    q_end_idx = BATCH_SIZE*batch_index + len(y_pred)\n","    for q_id, pred in zip(question_ids[BATCH_SIZE*batch_index:q_end_idx], y_pred):\n","        pred_df.loc[pred_df['question_id'] == q_id,'answer_text'] = pred"],"id":"6876e75d-f3ba-4007-a548-062d4b1ce681"},{"cell_type":"code","source":["pred_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"kJ1FASxgU1IS","executionInfo":{"status":"ok","timestamp":1668602374760,"user_tz":-540,"elapsed":7,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"9499030f-aa68-4a40-bfa6-83898961d343"},"id":"kJ1FASxgU1IS","execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          question_id answer_text\n","0     QUES_cyOI2451l1            \n","1     QUES_pz2vbWpWWo            \n","2     QUES_1g3jI4y7eo            \n","3     QUES_qzwOZwaeeY            \n","4     QUES_hfdtXCtdzf            \n","...               ...         ...\n","1621  QUES_JtsKBSQITG            \n","1622  QUES_IajaDLmxvq            \n","1623  QUES_lR6hjzsptY            \n","1624  QUES_ACwZJGYBfp            \n","1625  QUES_UB3Fj0NPIX            \n","\n","[1626 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-5b94f879-0b04-4bae-8660-837ca5cba4ad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question_id</th>\n","      <th>answer_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>QUES_cyOI2451l1</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>QUES_pz2vbWpWWo</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>QUES_1g3jI4y7eo</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>QUES_qzwOZwaeeY</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>QUES_hfdtXCtdzf</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1621</th>\n","      <td>QUES_JtsKBSQITG</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1622</th>\n","      <td>QUES_IajaDLmxvq</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1623</th>\n","      <td>QUES_lR6hjzsptY</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1624</th>\n","      <td>QUES_ACwZJGYBfp</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1625</th>\n","      <td>QUES_UB3Fj0NPIX</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1626 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b94f879-0b04-4bae-8660-837ca5cba4ad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5b94f879-0b04-4bae-8660-837ca5cba4ad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5b94f879-0b04-4bae-8660-837ca5cba4ad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":89}]},{"cell_type":"markdown","metadata":{"id":"2860d018-7dda-434f-97ef-cd59a0572c92"},"source":["###7.4 결과 저장"],"id":"2860d018-7dda-434f-97ef-cd59a0572c92"},{"cell_type":"code","execution_count":37,"metadata":{"id":"8f98cd03-5a99-4911-a72e-bc81e49c18be","executionInfo":{"status":"ok","timestamp":1668600191808,"user_tz":-540,"elapsed":3,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["# Set predict serial\n","kst = timezone(timedelta(hours=9))\n","predict_timestamp = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n","predict_serial = predict_timestamp\n","predict_serial\n","\n","PREDICT_DIR = os.path.join(PROJECT_DIR, 'results', 'predict', predict_serial)\n","os.makedirs(PREDICT_DIR, exist_ok=True)\n","\n","pred_df.to_csv(os.path.join(PREDICT_DIR, 'prediction.csv'), index=False)"],"id":"8f98cd03-5a99-4911-a72e-bc81e49c18be"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX6apf0nRz1Y"},"outputs":[],"source":[],"id":"SX6apf0nRz1Y"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}
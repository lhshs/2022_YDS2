{"cells":[{"cell_type":"markdown","metadata":{"id":"74d0cf9f-03f5-4446-be51-a96049fa0121"},"source":["# 문서 검색 효율화를 위한 기계독해\n","- 1차 모의경진대회(22.11.14 ~ 22.11.25)\n","- 자연어 기계독해(Machine Reading Comprehension) 과제"],"id":"74d0cf9f-03f5-4446-be51-a96049fa0121"},{"cell_type":"markdown","metadata":{"id":"NWNHSk-pSskv"},"source":["## 데이터 구조\n","\n","```\n","$ MRC/\n","├── DATA/\n","│   ├── train.json\n","│   ├── test.json\n","│   └── sample_submission.csv\n","├── prediction.csv (코드 실행 후 생성)\n","├── results/ (코드 실행 후 생성)\n","```"],"id":"NWNHSk-pSskv"},{"cell_type":"markdown","metadata":{"id":"xidLcL3yK3wm"},"source":["#0. 사전 준비"],"id":"xidLcL3yK3wm"},{"cell_type":"markdown","metadata":{"id":"qPmVS-p6K992"},"source":["##0.1 구글 드라이브 마운트"],"id":"qPmVS-p6K992"},{"cell_type":"code","execution_count":1,"metadata":{"id":"VHgjTjglFXf8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669030019421,"user_tz":-540,"elapsed":3019,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"a54c9fa3-863d-429b-f702-bf6939e3a84a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 구글 Colaboratory 를 사용하기 위해 구글 계정으로 로그인합니다. \n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"VHgjTjglFXf8"},{"cell_type":"markdown","metadata":{"id":"bYuiNxj7LQgH"},"source":["##0.2 라이브러리 설치"],"id":"bYuiNxj7LQgH"},{"cell_type":"code","execution_count":2,"metadata":{"id":"OchkeVlBLK_8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669030024912,"user_tz":-540,"elapsed":5494,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"811d78b0-1d92-4dfd-f5fe-1993ec0fe803"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"]}],"source":["!pip install transformers"],"id":"OchkeVlBLK_8"},{"cell_type":"markdown","metadata":{"id":"420e527f-ff52-4bb3-a260-565fe2f91e2d"},"source":["##1. 라이브러리 불러오기"],"id":"420e527f-ff52-4bb3-a260-565fe2f91e2d"},{"cell_type":"code","execution_count":3,"metadata":{"id":"5b80416a-1082-4ae9-8057-18eb163dfc15","executionInfo":{"status":"ok","timestamp":1669030038870,"user_tz":-540,"elapsed":11252,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["import os\n","import sys\n","import csv\n","import copy\n","import json\n","import random\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","from datetime import datetime, timezone, timedelta\n","\n","from transformers import ElectraTokenizerFast\n","from transformers import ElectraForQuestionAnswering\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"id":"5b80416a-1082-4ae9-8057-18eb163dfc15"},{"cell_type":"markdown","metadata":{"id":"e031838b-d5ad-4887-ae60-07ff98a71a0a"},"source":["##2. 하이퍼파라미터 및 기타 인자 설정"],"id":"e031838b-d5ad-4887-ae60-07ff98a71a0a"},{"cell_type":"markdown","metadata":{"id":"9e7be91e-9928-453e-8aeb-a6af032b7dcb"},"source":["###2.1 데이터 경로"],"id":"9e7be91e-9928-453e-8aeb-a6af032b7dcb"},{"cell_type":"code","execution_count":4,"metadata":{"id":"2bee580a-4c2a-42b4-9f1d-78b8d5e63981","executionInfo":{"status":"ok","timestamp":1669030038870,"user_tz":-540,"elapsed":7,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["PROJECT_DIR = '/content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC' # 프로젝트 디렉토리 설정\n","DATA_DIR= '/content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/DATA' # 데이터 디렉토리 설정"],"id":"2bee580a-4c2a-42b4-9f1d-78b8d5e63981"},{"cell_type":"markdown","metadata":{"id":"f923389a-631d-4a17-8542-382fa0d6e68b"},"source":["###2.2 시드 설정"],"id":"f923389a-631d-4a17-8542-382fa0d6e68b"},{"cell_type":"code","execution_count":5,"metadata":{"id":"97cb0fc4-cce7-45b7-876d-84d00a32f68c","executionInfo":{"status":"ok","timestamp":1669030038871,"user_tz":-540,"elapsed":7,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["# 난수 생성기가 항상 일정한 값을 출력하게 하기 위해 seed 고정\n","RANDOM_SEED = 42\n","\n","torch.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)"],"id":"97cb0fc4-cce7-45b7-876d-84d00a32f68c"},{"cell_type":"markdown","metadata":{"id":"88051bcc-8a4e-4552-af85-4fb62d9e2658"},"source":["###2.3 하이퍼파라미터 설정"],"id":"88051bcc-8a4e-4552-af85-4fb62d9e2658"},{"cell_type":"code","execution_count":6,"metadata":{"id":"42d42463-8bf9-4ea7-a42a-72f763adb515","executionInfo":{"status":"ok","timestamp":1669030038871,"user_tz":-540,"elapsed":6,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["LEARNING_RATE = 5.0e-4     # 학습률(learning rate)은 경사하강법(gradient descent)을 통해 내리막길을 내려갈 때의 보폭\n","BATCH_SIZE = 20    # 배치(batch)는 모델의 가중치(weights)를 업데이트하는 학습 데이터의 단위. 여기서는 16개를 학습할 때마다 모델의 가중치(weights)를 업데이트한다는 것\n","PIN_MEMORY = True\n","NUM_WORKERS = 0\n","EPOCHS = 2     # 에폭은 전체 학습 데이터를 학습에 사용하는 횟수. 주어진 학습 데이터를 여러번 학습할 수 있음\n","DROP_LAST = False\n","EARLY_STOPPING_MODE = min\n","EARLY_STOPPING_PATIENCE = 10\n","EARLY_STOPPING_TARGET = 'val_loss'     # validation set의 loss를 기준으로 early_stopping 여부를 결정할 것\n","LOGGING_INTERVAL = 200"],"id":"42d42463-8bf9-4ea7-a42a-72f763adb515"},{"cell_type":"markdown","metadata":{"id":"01a3191b-b482-4f9f-85e0-be96c5f09824"},"source":["###2.4 디바이스 설정"],"id":"01a3191b-b482-4f9f-85e0-be96c5f09824"},{"cell_type":"code","execution_count":7,"metadata":{"id":"626e7afa-2a56-4094-9e75-cfb3bec09606","executionInfo":{"status":"ok","timestamp":1669030038871,"user_tz":-540,"elapsed":6,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"626e7afa-2a56-4094-9e75-cfb3bec09606"},{"cell_type":"code","source":["# !nvidia-smi\n","print('Device:', device)\n","print('Current cuda device:', torch.cuda.current_device())\n","print('Count of using GPUs:', torch.cuda.device_count())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQUlqJJbI0Xi","executionInfo":{"status":"ok","timestamp":1669030038871,"user_tz":-540,"elapsed":6,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"504afddf-5341-40b5-e8f1-05651fd85117"},"id":"qQUlqJJbI0Xi","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Current cuda device: 0\n","Count of using GPUs: 1\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dnmi8biFJpKm","executionInfo":{"status":"ok","timestamp":1669030040436,"user_tz":-540,"elapsed":1570,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"dc74edb3-b586-49db-994e-f5e5ac161833"},"id":"Dnmi8biFJpKm","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Nov 21 11:27:18 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"863de192-3f18-421f-a06f-a5964bdbeb87"},"source":["##3. Dataset 정의"],"id":"863de192-3f18-421f-a06f-a5964bdbeb87"},{"cell_type":"code","execution_count":10,"metadata":{"id":"2c5fa64b-a355-43d2-95dc-94bb8605cc15","executionInfo":{"status":"ok","timestamp":1669030040437,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class QADataset(Dataset):     # 데이터를 input으로 변환해주는 Dataset 클래스를 상속하여, QA(Question Answering) 과제에 맞게 커스터마이징한다\n","    \n","    def __init__ (self, data_dir: str, tokenizer, max_seq_len: int, mode = 'train'):     # Dataset 클래스는 기본적으로 __init__, __len__, __getitem__를 정의해 주어야 한다\n","        self.mode = mode\n","        self.data = json.load(open(data_dir, 'r', encoding='utf8'))\n","        \n","        self.tokenizer = tokenizer\n","        self.max_seq_len = max_seq_len\n","        \n","        if mode == 'test':\n","            self.encodings, self.question_ids = self.preprocess()\n","        else:\n","            self.encodings, self.answers = self.preprocess()\n","        \n","    def __len__(self):     # index를 통해 input을 순차적으로 읽어오기 위해서는 데이터의 길이가 먼저 확인되어야 한다. __len__ 함수는 input의 길이를 반환해주는 함수\n","        return len(self.encodings.input_ids)\n","\n","    def __getitem__(self, index: int):     # input의 길이가 확인되면 index를 통해 데이터를 불러올 수 있다. __getitem__ 함수는 index에 해당하는 input 데이터를 반환해주는 함수\n","        return {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n","\n","    \n","    def preprocess(self):\n","        contexts, questions, answers, question_ids = self.read_squad()     # SQuAD(Stanford Question Answering Dataset) 형식의 데이터에서 contexts, questions, answers, question_ids를 읽어오는 함수\n","        if self.mode == 'test':\n","            encodings = self.tokenizer(contexts, questions, truncation=True, max_length = self.max_seq_len, padding=True)\n","            return encodings, question_ids\n","        else: # train or val\n","            self.add_end_idx(answers, contexts)     # train.json에는 질문에 대한 답이 context 내에서 시작되는 index인 'answer_srart'만 있기 때문에, 추가로 'answer_end'를 찾아주는 함수\n","            encodings = self.tokenizer(contexts, questions, truncation=True, max_length = self.max_seq_len, padding=True)\n","            self.add_token_positions(encodings, answers)\n","        \n","            return encodings, answers\n","        \n","    \n","    def read_squad(self):     # SQuAD(Stanford Question Answering Dataset) 형식의 데이터에서 contexts, questions, answers, question_ids를 읽어오는 함수\n","        contexts = []\n","        questions = []\n","        question_ids = []\n","        answers = []\n","        \n","        # train - val split\n","        if self.mode == 'train':\n","            self.data['data'] = self.data['data'][:-1*int(len(self.data['data'])*0.1)]\n","        elif self.mode == 'val':\n","            self.data['data'] = self.data['data'][-1*int(len(self.data['data'])*0.1):]\n","        \n","        \n","        till = len(self.data['data'])\n","        \n","\n","        for group in self.data['data'][:till]:\n","            for passage in group['paragraphs']:\n","                context = passage['context']\n","                for qa in passage['qas']:\n","                    question = qa['question']\n","                    if self.mode == 'test':\n","                        contexts.append(context)\n","                        questions.append(question)\n","                        question_ids.append(qa['question_id'])\n","                    else: # train or val\n","                        for ans in qa['answers']:\n","                            contexts.append(context)\n","                            questions.append(question)\n","\n","                            if qa['is_impossible']:\n","                                answers.append({'text':'','answer_start':-1})\n","                            else:\n","                                answers.append(ans)\n","                \n","        # return formatted data lists\n","        return contexts, questions, answers, question_ids\n","    \n","    \n","    def add_end_idx(self, answers, contexts):     # train.json에는 질문에 대한 답이 context 내에서 시작되는 index인 'answer_srart'만 있기 때문에, 추가로 'answer_end'를 찾아주는 함수\n","        for answer, context in zip(answers, contexts):\n","            gold_text = answer['text']\n","            start_idx = answer['answer_start']\n","            end_idx = start_idx + len(gold_text)\n","\n","            # in case the indices are off 1-2 idxs\n","            if context[start_idx:end_idx] == gold_text:\n","                answer['answer_end'] = end_idx\n","            else:\n","                for n in [1, 2]:\n","                    if context[start_idx-n:end_idx-n] == gold_text:\n","                        answer['answer_start'] = start_idx - n\n","                        answer['answer_end'] = end_idx - n\n","                    elif context[start_idx+n:end_idx+n] == gold_text:\n","                        answer['answer_start'] = start_idx + n\n","                        answer['answer_end'] = end_idx + n\n","                        \n","\n","    def add_token_positions(self, encodings, answers):\n","        # should use Fast tokenizer\n","        start_positions = []\n","        end_positions = []\n","        for i in range(len(answers)):\n","            if answers[i]['answer_start'] == -1:\n","                # set [CLS] token as answer if is_impossible\n","                start_positions.append(0)\n","                end_positions.append(1)\n","            else:\n","                start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","\n","                assert 'answer_end' in answers[i].keys(), f'no answer_end at {i}'\n","                end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n","\n","            # answer passage truncated\n","            if start_positions[-1] is None:\n","                start_positions[-1] = tokenizer.model_max_length                \n","            # end position cannot be found, shift until found\n","            shift = 1\n","            while end_positions[-1] is None:\n","                end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n","                shift += 1\n","                \n","        # char-based -> token based\n","        encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"],"id":"2c5fa64b-a355-43d2-95dc-94bb8605cc15"},{"cell_type":"markdown","metadata":{"id":"c5842a98-c4d9-477c-bfbb-db93a1bdca32"},"source":["##4. 모델 정의"],"id":"c5842a98-c4d9-477c-bfbb-db93a1bdca32"},{"cell_type":"code","execution_count":11,"metadata":{"id":"69904ef0-ec62-4eb2-8540-9f44a112fc1c","executionInfo":{"status":"ok","timestamp":1669030043117,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class electra(nn.Module):     # pytorch의 모든 neural network 모델들은 torch.nn.Module 클래스를 상속해야 한다. 기본적으로 __init__()과 forward 함수가 override(재정의)되어야 하며, forward 함수는 모델의 계산을 실행하는 것을 뜻한다.\n","\n","    def __init__(self, pretrained, **kwargs):\n","        super(electra, self).__init__()\n","\n","        self.model = ElectraForQuestionAnswering.from_pretrained(pretrained)     # Hugging Face에서 pretrain된 모델을 가져와서 model 변수에 저장한다.\n","        \n","\n","    def forward(self, input_ids, attention_mask, start_positions=None, end_positions=None):\n","        \n","        outputs = self.model(input_ids = input_ids, \n","                             attention_mask = attention_mask,\n","                             start_positions = start_positions,\n","                             end_positions = end_positions)\n","        \n","        return outputs"],"id":"69904ef0-ec62-4eb2-8540-9f44a112fc1c"},{"cell_type":"markdown","metadata":{"id":"9615d17d-1f80-45e9-8583-e4b3f3a84f44"},"source":["##5. Utils 정의\n","###5.1 EarlyStopper"],"id":"9615d17d-1f80-45e9-8583-e4b3f3a84f44"},{"cell_type":"code","execution_count":12,"metadata":{"id":"e9ea7473-7a39-48d9-a0c7-5ef197c99547","executionInfo":{"status":"ok","timestamp":1669030043969,"user_tz":-540,"elapsed":1,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class EarlyStopper():     # 일정 기간 모델 성능에 개선이 없으면, 학습을 중단하는 기능\n","\n","    def __init__(self, patience: int, mode:str)-> None:\n","        self.patience = patience\n","        self.mode = mode\n","\n","        # Initiate\n","        self.patience_counter = 0\n","        self.stop = False\n","        self.best_loss = np.inf\n","\n","        print(f\"Initiated early stopper, mode: {self.mode}, best score: {self.best_loss}, patience: {self.patience}\")\n","\n","        \n","    def check_early_stopping(self, loss: float)-> None:\n","        loss = -loss if self.mode == 'max' else loss  # get max value if mode set to max\n","\n","        if loss > self.best_loss:\n","            # got worse score\n","            self.patience_counter += 1\n","\n","            print(f\"Early stopper, counter {self.patience_counter}/{self.patience}, best:{abs(self.best_loss)} -> now:{abs(loss)}\")\n","            \n","            if self.patience_counter == self.patience:\n","                print(f\"Early stopper, stop\")\n","                self.stop = True  # end\n","\n","        elif loss <= self.best_loss:\n","            # got better score\n","            self.patience_counter = 0\n","            \n","            print(f\"Early stopper, counter {self.patience_counter}/{self.patience}, best:{abs(self.best_loss)} -> now:{abs(loss)}\")\n","            print(f\"Set counter as {self.patience_counter}\")\n","            print(f\"Update best score as {abs(loss)}\")\n","            \n","            self.best_loss = loss\n","            \n","        else:\n","            print('debug')"],"id":"e9ea7473-7a39-48d9-a0c7-5ef197c99547"},{"cell_type":"markdown","metadata":{"id":"c53b4cda-5607-4a52-ad4b-a0ae33940004"},"source":["###5.2 Trainer"],"id":"c53b4cda-5607-4a52-ad4b-a0ae33940004"},{"cell_type":"code","execution_count":13,"metadata":{"id":"636e914f-d8cb-47b4-8fa0-3f6918653ae0","executionInfo":{"status":"ok","timestamp":1669030045367,"user_tz":-540,"elapsed":2,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class Trainer():     # 학습을 위한 Trainer 클래스 정의\n","\n","    def __init__(self,\n","                 model,\n","                 optimizer,\n","                 loss,\n","                 metrics,\n","                 device,\n","                 tokenizer,\n","                 interval=100):\n","        \n","        self.model = model\n","        self.optimizer = optimizer\n","        self.loss = loss\n","        self.metrics = metrics\n","        self.device = device\n","        self.interval = interval\n","        self.tokenizer = tokenizer\n","\n","        # History\n","        self.loss_sum = 0  # Epoch loss sum\n","        self.loss_mean = 0 # Epoch loss mean\n","        self.y = list()\n","        self.y_preds = list()\n","        self.score_dict = dict()  # metric score\n","        self.elapsed_time = 0\n","        \n","\n","    def train(self, mode, dataloader, tokenizer, epoch_index=0):\n","        \n","        start_timestamp = time()\n","        self.model.train() if mode == 'train' else self.model.eval()     # 모델을 train(eval) mode로 전환.  train(eval) mode에서는 dropout, batchnorm이 적용된다(적용되지 않는다)\n"," \n","        for batch_index, batch in enumerate(tqdm(dataloader, leave=True)):\n","            \n","            self.optimizer.zero_grad()     # 파라미터 업데이트는 batch 단위로 이루어지고, 매 batch마다 이전 스텝에서 계산된 gradient를 초기화해주어야 함\n","            # pull all the tensor batches required for training\n","            input_ids = batch['input_ids'].to(self.device)\n","            attention_mask = batch['attention_mask'].to(self.device)\n","            start_positions = batch['start_positions'].to(self.device)\n","            end_positions = batch['end_positions'].to(self.device)\n","            \n","            # train model on batch and return outputs (incl. loss)\n","            # Inference\n","            outputs = self.model(input_ids, attention_mask=attention_mask,\n","                            start_positions=start_positions,\n","                            end_positions=end_positions)\n","            \n","            loss = outputs.loss\n","            start_score = outputs.start_logits\n","            end_score = outputs.end_logits\n","            \n","            \n","            start_idx = torch.argmax(start_score, dim=1).cpu().tolist()\n","            end_idx = torch.argmax(end_score, dim=1).cpu().tolist()\n","            \n","            # Update\n","            if mode == 'train':\n","                loss.backward()     # backpropagation\n","                self.optimizer.step()     # 파라미터 업데이트\n","                \n","            elif mode in ['val', 'test']:\n","                pass\n","            \n","            # History\n","            self.loss_sum += loss.item()\n","            \n","            # create answer; list of strings\n","            for i in range(len(input_ids)):\n","                if start_idx[i] > end_idx[i]:\n","                    output = ''\n","                \n","                self.y_preds.append(self.tokenizer.decode(input_ids[i][start_idx[i]:end_idx[i]]))\n","                self.y.append(self.tokenizer.decode(input_ids[i][start_positions[i]:end_positions[i]]))\n","\n","\n","            # Logging\n","            if batch_index % self.interval == 0:\n","                print(f\"batch: {batch_index}/{len(dataloader)} loss: {loss.item()}\")\n","                \n","        # Epoch history\n","        self.loss_mean = self.loss_sum / len(dataloader)  # Epoch loss mean\n","\n","        # Metric\n","        score = self.metrics(self.y, self.y_preds)\n","        self.score_dict['metric_name'] = score\n","\n","        # Elapsed time\n","        end_timestamp = time()\n","        self.elapsed_time = end_timestamp - start_timestamp\n","\n","    def clear_history(self):\n","        self.loss_sum = 0\n","        self.loss_mean = 0\n","        self.y_preds = list()\n","        self.y = list()\n","        self.score_dict = dict()\n","        self.elapsed_time = 0"],"id":"636e914f-d8cb-47b4-8fa0-3f6918653ae0"},{"cell_type":"markdown","metadata":{"id":"1f530fc6-25e7-4b9c-9431-7a5ea267c348"},"source":["###5.3 Recorder"],"id":"1f530fc6-25e7-4b9c-9431-7a5ea267c348"},{"cell_type":"code","execution_count":14,"metadata":{"id":"89b61d3c-858b-4213-a1c1-8f32bed3698a","executionInfo":{"status":"ok","timestamp":1669030050309,"user_tz":-540,"elapsed":1153,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["class Recorder():\n","\n","    def __init__(self,\n","                 record_dir: str,\n","                 model: object,\n","                 optimizer: object):\n","        \n","        self.record_dir = record_dir\n","        self.record_filepath = os.path.join(self.record_dir, 'record.csv')\n","        self.weight_path = os.path.join(record_dir, 'model.pt')\n","\n","        self.model = model\n","        self.optimizer = optimizer\n","\n","        \n","    def set_model(self, model: 'model'):\n","        self.model = model\n","\n","\n","    def add_row(self, row_dict: dict):\n","\n","        fieldnames = list(row_dict.keys())\n","\n","        with open(self.record_filepath, newline='', mode='a') as f:\n","            writer = csv.DictWriter(f, fieldnames=fieldnames)\n","\n","            if f.tell() == 0:\n","                writer.writeheader()\n","\n","            writer.writerow(row_dict)\n","            print(f\"Write row {row_dict['epoch_index']}\")\n","\n","            \n","    def save_weight(self, epoch: int)-> None:\n","        check_point = {\n","            'epoch': epoch + 1,\n","            'model': self.model.state_dict(),\n","            'optimizer': self.optimizer.state_dict(),\n","        }\n","        \n","        torch.save(check_point, self.weight_path)\n","        print(f\"Recorder, epoch {epoch} Model saved: {self.weight_path}\")"],"id":"89b61d3c-858b-4213-a1c1-8f32bed3698a"},{"cell_type":"markdown","metadata":{"id":"66c1c276-2264-43b9-aa62-44cfd81ee395"},"source":["##6. 모델 학습"],"id":"66c1c276-2264-43b9-aa62-44cfd81ee395"},{"cell_type":"markdown","metadata":{"id":"aa925da6-d006-4fb9-a763-021ffe9bc8e4"},"source":["###6.1 모델과 기타 utils 설정"],"id":"aa925da6-d006-4fb9-a763-021ffe9bc8e4"},{"cell_type":"code","execution_count":15,"metadata":{"id":"714f8a41-c14f-4fc5-84ae-b04f0452a952","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669030060947,"user_tz":-540,"elapsed":7936,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"5c5886ef-fcae-451a-9859-edb20866f332"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Initiated early stopper, mode: <built-in function min>, best score: inf, patience: 10\n"]}],"source":["# Load model\n","model = electra(pretrained='monologg/koelectra-small-v3-discriminator').to(device)\n","\n","# Set optimizer, loss function, metric function\n","# optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n","optimizer = optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n","# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","loss = F.cross_entropy\n","metrics = accuracy_score\n","\n","# Set tokenizer\n","tokenizer = ElectraTokenizerFast.from_pretrained('monologg/koelectra-small-v3-discriminator')\n","# klue/roberta-large\n","# monologg/koelectra-small-v3-discriminator\n","\n","# Set Trainer\n","trainer = Trainer(model=model,\n","                  optimizer=optimizer,\n","                  loss=loss,\n","                  metrics=metrics,\n","                  device=device,\n","                  tokenizer=tokenizer,\n","                  interval=LOGGING_INTERVAL)\n","\n","# Set earlystopper\n","early_stopper = EarlyStopper(patience=EARLY_STOPPING_PATIENCE,\n","                            mode=min)\n","\n","# Set train serial\n","kst = timezone(timedelta(hours=9))\n","train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n","\n","\n","# Set recorder \n","RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n","os.makedirs(RECORDER_DIR, exist_ok=True)\n","\n","recorder = Recorder(record_dir=RECORDER_DIR,\n","                    model=model,\n","                    optimizer=optimizer)"],"id":"714f8a41-c14f-4fc5-84ae-b04f0452a952"},{"cell_type":"markdown","metadata":{"id":"c715ceb0-4555-431a-ab9d-8f6f99dd783f"},"source":["###6.2 Dataset & Dataloader 설정"],"id":"c715ceb0-4555-431a-ab9d-8f6f99dd783f"},{"cell_type":"code","execution_count":16,"metadata":{"id":"d504be1e-67c8-4de5-b8d0-225ac0b8fd65","colab":{"base_uri":"https://localhost:8080/","height":179},"executionInfo":{"status":"ok","timestamp":1669026104241,"user_tz":-540,"elapsed":6,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"14532358-9e90-48f5-afc4-3603328f6bbd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# torch.utils.data.Dataset : 데이터를 input으로 변환\\ntrain_dataset = QADataset(data_dir=os.path.join(DATA_DIR, \\'train.json\\'), tokenizer = tokenizer, max_seq_len = 512, mode = \\'train\\')\\nval_dataset = QADataset(data_dir=os.path.join(DATA_DIR, \\'train.json\\'), tokenizer = tokenizer, max_seq_len = 512, mode = \\'val\\')\\n\\n# torch.utils.data.DataLoader : input을 배치 단위로 리턴해주는 기능\\ntrain_dataloader = DataLoader(dataset=train_dataset,\\n                              batch_size=BATCH_SIZE,\\n                              num_workers=NUM_WORKERS, \\n                              shuffle=True,\\n                              pin_memory=PIN_MEMORY,\\n                              drop_last=DROP_LAST)\\n\\nval_dataloader = DataLoader(dataset=val_dataset,\\n                            batch_size=BATCH_SIZE,\\n                            num_workers=NUM_WORKERS, \\n                            shuffle=True,\\n                            pin_memory=PIN_MEMORY,\\n                            drop_last=DROP_LAST)\\n\\nprint(f\"Load data, train:{len(train_dataset)} val:{len(val_dataset)}\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["'''\n","# torch.utils.data.Dataset : 데이터를 input으로 변환\n","train_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'train')\n","val_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'val')\n","\n","# torch.utils.data.DataLoader : input을 배치 단위로 리턴해주는 기능\n","train_dataloader = DataLoader(dataset=train_dataset,\n","                              batch_size=BATCH_SIZE,\n","                              num_workers=NUM_WORKERS, \n","                              shuffle=True,\n","                              pin_memory=PIN_MEMORY,\n","                              drop_last=DROP_LAST)\n","\n","val_dataloader = DataLoader(dataset=val_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            num_workers=NUM_WORKERS, \n","                            shuffle=True,\n","                            pin_memory=PIN_MEMORY,\n","                            drop_last=DROP_LAST)\n","\n","print(f\"Load data, train:{len(train_dataset)} val:{len(val_dataset)}\")\n","'''"],"id":"d504be1e-67c8-4de5-b8d0-225ac0b8fd65"},{"cell_type":"code","source":["# torch.utils.data.Dataset : 데이터를 input으로 변환\n","train_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'AI_train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'train')\n","# train_dataset2 = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'train')\n","\n","print(f\"Load data, train:{len(train_dataset)}\")\n","# print(f\"Load data, train:{len(train_dataset2)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2FmLehXemMA-","executionInfo":{"status":"ok","timestamp":1669030127615,"user_tz":-540,"elapsed":45200,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"b28adcc2-2a3c-45b0-8cc5-076341905bec"},"id":"2FmLehXemMA-","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Load data, train:106128\n"]}]},{"cell_type":"code","source":["'''\n","train_dataset3 = train_dataset + train_dataset2\n","print(f\"Load data, train:{len(train_dataset3)} \") # val:{len(val_dataset)}\")\n","'''"],"metadata":{"id":"hIOEyfn1mQ_t","executionInfo":{"status":"aborted","timestamp":1669026169772,"user_tz":-540,"elapsed":8,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"id":"hIOEyfn1mQ_t","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(dataset=train_dataset,\n","                              batch_size=BATCH_SIZE,\n","                              num_workers=NUM_WORKERS, \n","                              shuffle=True,\n","                              pin_memory=PIN_MEMORY,\n","                              drop_last=DROP_LAST)"],"metadata":{"id":"qiJxs-_nmW3O","executionInfo":{"status":"ok","timestamp":1669030127615,"user_tz":-540,"elapsed":17,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"id":"qiJxs-_nmW3O","execution_count":17,"outputs":[]},{"cell_type":"code","source":["val_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'AI_train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'val')\n","# val_dataset2 = QADataset(data_dir=os.path.join(DATA_DIR, 'train.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'val')\n","\n","print(f\"Load data, train:{len(val_dataset)}\")\n","# print(f\"Load data, train:{len(val_dataset2)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mszINbQymZWm","executionInfo":{"status":"ok","timestamp":1669030134793,"user_tz":-540,"elapsed":7194,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"a6721322-9b8f-4703-a5c7-a51cc39a76f3"},"id":"mszINbQymZWm","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Load data, train:13512\n"]}]},{"cell_type":"code","source":["'''\n","val_dataset3 = val_dataset + val_dataset2\n","print(f\"Load data, val:{len(val_dataset3)} \") \n","'''"],"metadata":{"id":"xlhyg_n-mZPF","executionInfo":{"status":"aborted","timestamp":1669026169773,"user_tz":-540,"elapsed":9,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"id":"xlhyg_n-mZPF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_dataloader = DataLoader(dataset=val_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            num_workers=NUM_WORKERS, \n","                            shuffle=True,\n","                            pin_memory=PIN_MEMORY,\n","                            drop_last=DROP_LAST)"],"metadata":{"id":"uBGPeBTRmcjj","executionInfo":{"status":"ok","timestamp":1669030134794,"user_tz":-540,"elapsed":21,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"id":"uBGPeBTRmcjj","execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3e685537-7c8b-439c-8258-00c658bb360a"},"source":["###6.3 Epoch 단위 학습 진행"],"id":"3e685537-7c8b-439c-8258-00c658bb360a"},{"cell_type":"code","source":["# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512"],"metadata":{"id":"EE9z_axSFokI"},"id":"EE9z_axSFokI","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"661bf57c-20d2-4e14-bffb-e7db7eb85f78","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669033401994,"user_tz":-540,"elapsed":3267220,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"40057152-9d4d-4f65-ee7b-54f1535c37d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train 0/2\n","--Train 0/2\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/5306 [00:02<3:33:17,  2.41s/it]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/5306 loss: 6.097280502319336\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 201/5306 [00:57<23:41,  3.59it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/5306 loss: 2.0061466693878174\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 401/5306 [01:54<23:15,  3.52it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 400/5306 loss: 2.081408977508545\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█▏        | 601/5306 [02:52<22:15,  3.52it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 600/5306 loss: 1.7726274728775024\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 801/5306 [03:50<21:52,  3.43it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 800/5306 loss: 1.4184608459472656\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 1001/5306 [04:48<20:41,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1000/5306 loss: 1.1594948768615723\n"]},{"output_type":"stream","name":"stderr","text":[" 23%|██▎       | 1201/5306 [05:46<19:45,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1200/5306 loss: 1.193901777267456\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 1401/5306 [06:44<18:48,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1400/5306 loss: 1.036330223083496\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 1601/5306 [07:42<17:52,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1600/5306 loss: 1.201899528503418\n"]},{"output_type":"stream","name":"stderr","text":[" 34%|███▍      | 1801/5306 [08:40<17:00,  3.43it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1800/5306 loss: 1.2312896251678467\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 2001/5306 [09:38<15:55,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2000/5306 loss: 1.4633071422576904\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████▏     | 2201/5306 [10:36<15:05,  3.43it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2200/5306 loss: 1.4702510833740234\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 2401/5306 [11:34<14:33,  3.33it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2400/5306 loss: 1.166877031326294\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 2601/5306 [12:32<13:13,  3.41it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2600/5306 loss: 1.8957993984222412\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 2801/5306 [13:30<12:02,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2800/5306 loss: 1.2905688285827637\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 3001/5306 [14:28<11:14,  3.42it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3000/5306 loss: 1.282942771911621\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 3201/5306 [15:26<10:06,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3200/5306 loss: 0.3872619569301605\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▍   | 3401/5306 [16:24<09:11,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3400/5306 loss: 0.9050285220146179\n"]},{"output_type":"stream","name":"stderr","text":[" 68%|██████▊   | 3601/5306 [17:22<08:11,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3600/5306 loss: 1.0574480295181274\n"]},{"output_type":"stream","name":"stderr","text":[" 72%|███████▏  | 3801/5306 [18:20<07:17,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3800/5306 loss: 0.9419869184494019\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 4001/5306 [19:18<06:18,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4000/5306 loss: 1.0904759168624878\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▉  | 4201/5306 [20:16<05:19,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4200/5306 loss: 1.002315878868103\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 4401/5306 [21:14<04:19,  3.48it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4400/5306 loss: 1.1483268737792969\n"]},{"output_type":"stream","name":"stderr","text":[" 87%|████████▋ | 4601/5306 [22:12<03:22,  3.48it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4600/5306 loss: 1.1201850175857544\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 4801/5306 [23:10<02:25,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4800/5306 loss: 1.1958630084991455\n"]},{"output_type":"stream","name":"stderr","text":[" 94%|█████████▍| 5001/5306 [24:08<01:28,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 5000/5306 loss: 1.2316328287124634\n"]},{"output_type":"stream","name":"stderr","text":[" 98%|█████████▊| 5201/5306 [25:05<00:30,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 5200/5306 loss: 1.1553043127059937\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5306/5306 [25:36<00:00,  3.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val 0/2\n","--Val 0/2\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 2/675 [00:00<01:02, 10.78it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/675 loss: 0.8037025332450867\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|██▉       | 202/675 [00:19<00:46, 10.18it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/675 loss: 1.1759521961212158\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 402/675 [00:38<00:25, 10.50it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 400/675 loss: 1.2113394737243652\n"]},{"output_type":"stream","name":"stderr","text":[" 89%|████████▉ | 602/675 [00:57<00:06, 10.55it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 600/675 loss: 2.0144705772399902\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 675/675 [01:04<00:00, 10.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Write row 0\n","Early stopper, counter 0/10, best:inf -> now:1.0793779963034171\n","Set counter as 0\n","Update best score as 1.0793779963034171\n","Recorder, epoch 0 Model saved: /content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/results/train/20221121_202740/model.pt\n","Train 1/2\n","--Train 1/2\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/5306 [00:00<25:55,  3.41it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/5306 loss: 1.0723776817321777\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 201/5306 [00:58<24:35,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/5306 loss: 0.7653268575668335\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 401/5306 [01:56<23:34,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 400/5306 loss: 1.07666015625\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█▏        | 601/5306 [02:54<22:40,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 600/5306 loss: 1.2659580707550049\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 801/5306 [03:52<21:39,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 800/5306 loss: 0.962070107460022\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 1001/5306 [04:50<20:50,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1000/5306 loss: 0.5896621346473694\n"]},{"output_type":"stream","name":"stderr","text":[" 23%|██▎       | 1201/5306 [05:47<19:42,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1200/5306 loss: 0.8851637840270996\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 1401/5306 [06:45<18:49,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1400/5306 loss: 1.3529481887817383\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 1601/5306 [07:43<17:49,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1600/5306 loss: 0.8355503678321838\n"]},{"output_type":"stream","name":"stderr","text":[" 34%|███▍      | 1801/5306 [08:41<16:49,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 1800/5306 loss: 1.139141321182251\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 2001/5306 [09:39<15:56,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2000/5306 loss: 0.7301837801933289\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████▏     | 2201/5306 [10:37<14:55,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2200/5306 loss: 0.9010317325592041\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 2401/5306 [11:35<14:02,  3.45it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2400/5306 loss: 1.2282500267028809\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 2601/5306 [12:33<13:01,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2600/5306 loss: 0.8904396891593933\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 2801/5306 [13:31<12:36,  3.31it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 2800/5306 loss: 1.0048015117645264\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 3001/5306 [14:28<11:23,  3.37it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3000/5306 loss: 0.5522158145904541\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 3201/5306 [15:26<10:06,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3200/5306 loss: 1.0766043663024902\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▍   | 3401/5306 [16:24<09:10,  3.46it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3400/5306 loss: 1.147250771522522\n"]},{"output_type":"stream","name":"stderr","text":[" 68%|██████▊   | 3601/5306 [17:22<08:10,  3.48it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3600/5306 loss: 1.2335906028747559\n"]},{"output_type":"stream","name":"stderr","text":[" 72%|███████▏  | 3801/5306 [18:20<07:17,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 3800/5306 loss: 1.0735461711883545\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 4001/5306 [19:17<06:15,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4000/5306 loss: 1.0574977397918701\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▉  | 4201/5306 [20:15<05:17,  3.48it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4200/5306 loss: 1.5012662410736084\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 4401/5306 [21:13<04:20,  3.47it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4400/5306 loss: 1.0503668785095215\n"]},{"output_type":"stream","name":"stderr","text":[" 87%|████████▋ | 4601/5306 [22:11<03:49,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4600/5306 loss: 0.8314367532730103\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 4801/5306 [23:17<02:48,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 4800/5306 loss: 0.7750580310821533\n"]},{"output_type":"stream","name":"stderr","text":[" 94%|█████████▍| 5001/5306 [24:24<01:40,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 5000/5306 loss: 0.6859911680221558\n"]},{"output_type":"stream","name":"stderr","text":[" 98%|█████████▊| 5201/5306 [25:30<00:34,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 5200/5306 loss: 1.1635366678237915\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5306/5306 [26:05<00:00,  3.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val 1/2\n","--Val 1/2\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/675 [00:00<01:38,  6.83it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 0/675 loss: 0.7045469284057617\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|██▉       | 202/675 [00:28<01:06,  7.08it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 200/675 loss: 1.2186768054962158\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 402/675 [00:57<00:38,  7.08it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 400/675 loss: 1.264329195022583\n"]},{"output_type":"stream","name":"stderr","text":[" 89%|████████▉ | 602/675 [01:25<00:10,  7.07it/s]"]},{"output_type":"stream","name":"stdout","text":["batch: 600/675 loss: 0.9629223346710205\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 675/675 [01:36<00:00,  7.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Write row 1\n","Early stopper, counter 0/10, best:1.0793779963034171 -> now:1.0201761136673115\n","Set counter as 0\n","Update best score as 1.0201761136673115\n","Recorder, epoch 1 Model saved: /content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/results/train/20221121_202740/model.pt\n"]}],"source":["# Train\n","for epoch_index in range(EPOCHS):\n","\n","    # Set Recorder row\n","    row_dict = dict()\n","    row_dict['epoch_index'] = epoch_index\n","    row_dict['train_serial'] = train_serial\n","\n","    \"\"\"\n","    Train\n","    \"\"\"\n","    print(f\"Train {epoch_index}/{EPOCHS}\")\n","    print(f\"--Train {epoch_index}/{EPOCHS}\")\n","    trainer.train(dataloader=train_dataloader, epoch_index=epoch_index, tokenizer=tokenizer, mode='train')\n","\n","    row_dict['train_loss'] = trainer.loss_mean\n","    row_dict['train_elapsed_time'] = trainer.elapsed_time \n","\n","    for metric_str, score in trainer.score_dict.items():\n","        row_dict[f\"train_{metric_str}\"] = score\n","    trainer.clear_history()\n","\n","    \"\"\"\n","    Validation\n","    \"\"\"\n","    print(f\"Val {epoch_index}/{EPOCHS}\")\n","    print(f\"--Val {epoch_index}/{EPOCHS}\")\n","    trainer.train(dataloader=val_dataloader, epoch_index=epoch_index, tokenizer=tokenizer, mode='val')\n","\n","    row_dict['val_loss'] = trainer.loss_mean\n","    row_dict['val_elapsed_time'] = trainer.elapsed_time \n","\n","    for metric_str, score in trainer.score_dict.items():\n","        row_dict[f\"val_{metric_str}\"] = score\n","    trainer.clear_history()\n","\n","    \"\"\"\n","    Record\n","    \"\"\"\n","    recorder.add_row(row_dict)\n","\n","    \"\"\"\n","    Early stopper\n","    \"\"\"\n","    early_stopping_target = EARLY_STOPPING_TARGET\n","    early_stopper.check_early_stopping(loss=row_dict[early_stopping_target])\n","\n","    if early_stopper.patience_counter == 0:\n","        recorder.save_weight(epoch=epoch_index)\n","        best_row_dict = copy.deepcopy(row_dict)\n","\n","    if early_stopper.stop == True:\n","        print(f\"Early stopped, counter {early_stopper.patience_counter}/{EARLY_STOPPING_PATIENCE}\")\n","\n","        break"],"id":"661bf57c-20d2-4e14-bffb-e7db7eb85f78"},{"cell_type":"code","source":["type(val_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kPdtzUBur2lo","executionInfo":{"status":"ok","timestamp":1669025815884,"user_tz":-540,"elapsed":628,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"2bc9bf90-4dbd-4f03-f019-171e9bcc638d"},"id":"kPdtzUBur2lo","execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.utils.data.dataloader.DataLoader"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["row_dict\n","# train_loss = row_dict['train_loss']\n","# val_loss = row_dict['val_loss']\n","# plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBll-fup8xxG","executionInfo":{"status":"ok","timestamp":1669029362788,"user_tz":-540,"elapsed":636,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"c241afac-137f-45e3-b2cd-028a7e77f66e"},"id":"GBll-fup8xxG","execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'epoch_index': 1,\n"," 'train_serial': '20221121_192143',\n"," 'train_loss': 0.8400932408662891,\n"," 'train_elapsed_time': 1499.973861694336,\n"," 'train_metric_name': 0.6905717624001206,\n"," 'val_loss': 0.9580538479028943,\n"," 'val_elapsed_time': 89.3628511428833,\n"," 'val_metric_name': 0.6887211367673179}"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"ed9d2987-378c-45df-84bf-ee4589ac61d4"},"source":["##7. 추론"],"id":"ed9d2987-378c-45df-84bf-ee4589ac61d4"},{"cell_type":"markdown","metadata":{"id":"0dee7dae-24d0-4cf3-b641-c3938ceda233"},"source":["###7.1 테스트 Dataset & Dataloader 설정"],"id":"0dee7dae-24d0-4cf3-b641-c3938ceda233"},{"cell_type":"code","execution_count":21,"metadata":{"id":"a67fcd63-de84-41fe-a620-8771d799722b","executionInfo":{"status":"ok","timestamp":1669033487684,"user_tz":-540,"elapsed":2305,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["# Load data\n","test_dataset = QADataset(data_dir=os.path.join(DATA_DIR, 'test.json'), tokenizer = tokenizer, max_seq_len = 512, mode = 'test')\n","\n","question_ids = test_dataset.question_ids\n","\n","test_dataloader = DataLoader(dataset=test_dataset,\n","                            batch_size=BATCH_SIZE,\n","                            num_workers=NUM_WORKERS, \n","                            shuffle=False,\n","                            pin_memory=PIN_MEMORY,\n","                            drop_last=DROP_LAST)"],"id":"a67fcd63-de84-41fe-a620-8771d799722b"},{"cell_type":"markdown","metadata":{"id":"733f8fc5-d1e8-4027-b8c7-ed87ec409246"},"source":["###7.2 모델 로드"],"id":"733f8fc5-d1e8-4027-b8c7-ed87ec409246"},{"cell_type":"code","execution_count":22,"metadata":{"id":"86cc6eeb-6f7c-4765-9478-83cb9ce62954","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669033492635,"user_tz":-540,"elapsed":2216,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"c15038a7-6cc6-4ed3-b66f-f7a3d91fce8c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at monologg/koelectra-small-v3-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"source":["# Load model\n","\n","model = electra(pretrained='monologg/koelectra-small-v3-discriminator').to(device)\n","\n","checkpoint = torch.load(os.path.join(RECORDER_DIR, 'model.pt'))\n","\n","model.load_state_dict(checkpoint['model'])"],"id":"86cc6eeb-6f7c-4765-9478-83cb9ce62954"},{"cell_type":"code","source":["RECORDER_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"_h2ZKq5Tctw_","executionInfo":{"status":"ok","timestamp":1669033495061,"user_tz":-540,"elapsed":6,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"2af96ca7-1e79-43c6-ef6f-7c466ca7e138"},"id":"_h2ZKq5Tctw_","execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/YDS/AIConnet_YDS_1/NLP_MRC/results/train/20221121_202740'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"ea6e2ce2-c11a-42b0-baaa-107251e077a3"},"source":["###7.3 추론 진행"],"id":"ea6e2ce2-c11a-42b0-baaa-107251e077a3"},{"cell_type":"code","execution_count":27,"metadata":{"id":"6876e75d-f3ba-4007-a548-062d4b1ce681","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669033598475,"user_tz":-540,"elapsed":9127,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"8840c4d9-d494-4c4a-ef45-d683018c2138"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 81/81 [00:08<00:00,  9.29it/s]\n"]}],"source":["model.eval()     # 모델을 eval mode로 전환. train mode와 달리 eval mode에서는 dropout, batchnorm이 적용되지 않는다\n","\n","pred_df = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))\n","\n","for batch_index, batch in enumerate(tqdm(test_dataloader, leave=True)):\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","\n","    # Inference\n","    outputs = model(input_ids, attention_mask=attention_mask)\n","\n","    start_score = outputs.start_logits\n","    end_score = outputs.end_logits\n","\n","    start_idx = torch.argmax(start_score, dim=1).cpu().tolist()\n","    end_idx = torch.argmax(end_score, dim=1).cpu().tolist()\n","\n","    y_pred = []\n","    for i in range(len(input_ids)):\n","        if start_idx[i] > end_idx[i]:\n","            output = ''\n","\n","        ans_txt = tokenizer.decode(input_ids[i][start_idx[i]:end_idx[i]]).replace('#','')\n","\n","        if ans_txt == '[CLS]':\n","            ans_txt == ''\n","\n","        y_pred.append(ans_txt)\n","\n","\n","    q_end_idx = BATCH_SIZE*batch_index + len(y_pred)\n","    for q_id, pred in zip(question_ids[BATCH_SIZE*batch_index:q_end_idx], y_pred):\n","        pred_df.loc[pred_df['question_id'] == q_id,'answer_text'] = pred"],"id":"6876e75d-f3ba-4007-a548-062d4b1ce681"},{"cell_type":"code","source":["pred_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"kJ1FASxgU1IS","executionInfo":{"status":"ok","timestamp":1669033600596,"user_tz":-540,"elapsed":3,"user":{"displayName":"hs L","userId":"04521576200392151172"}},"outputId":"92c7dbb7-0963-43fc-cdeb-3c678efba244"},"id":"kJ1FASxgU1IS","execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          question_id answer_text\n","0     QUES_cyOI2451l1  한국원자력안전기술원\n","1     QUES_pz2vbWpWWo    가출청소년 문제\n","2     QUES_1g3jI4y7eo       [CLS]\n","3     QUES_qzwOZwaeeY   Prime Air\n","4     QUES_hfdtXCtdzf    장애인케어서비스\n","...               ...         ...\n","1621  QUES_JtsKBSQITG         NaN\n","1622  QUES_IajaDLmxvq         NaN\n","1623  QUES_lR6hjzsptY         NaN\n","1624  QUES_ACwZJGYBfp         NaN\n","1625  QUES_UB3Fj0NPIX         NaN\n","\n","[1626 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-0d6baa35-cdce-4252-8c03-1f8a40fcf861\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question_id</th>\n","      <th>answer_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>QUES_cyOI2451l1</td>\n","      <td>한국원자력안전기술원</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>QUES_pz2vbWpWWo</td>\n","      <td>가출청소년 문제</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>QUES_1g3jI4y7eo</td>\n","      <td>[CLS]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>QUES_qzwOZwaeeY</td>\n","      <td>Prime Air</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>QUES_hfdtXCtdzf</td>\n","      <td>장애인케어서비스</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1621</th>\n","      <td>QUES_JtsKBSQITG</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1622</th>\n","      <td>QUES_IajaDLmxvq</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1623</th>\n","      <td>QUES_lR6hjzsptY</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1624</th>\n","      <td>QUES_ACwZJGYBfp</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1625</th>\n","      <td>QUES_UB3Fj0NPIX</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1626 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d6baa35-cdce-4252-8c03-1f8a40fcf861')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0d6baa35-cdce-4252-8c03-1f8a40fcf861 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0d6baa35-cdce-4252-8c03-1f8a40fcf861');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"2860d018-7dda-434f-97ef-cd59a0572c92"},"source":["###7.4 결과 저장"],"id":"2860d018-7dda-434f-97ef-cd59a0572c92"},{"cell_type":"code","execution_count":29,"metadata":{"id":"8f98cd03-5a99-4911-a72e-bc81e49c18be","executionInfo":{"status":"ok","timestamp":1669033605239,"user_tz":-540,"elapsed":472,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["# Set predict serial\n","kst = timezone(timedelta(hours=9))\n","predict_timestamp = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n","predict_serial = predict_timestamp\n","predict_serial\n","\n","PREDICT_DIR = os.path.join(PROJECT_DIR, 'results', 'predict', predict_serial)\n","os.makedirs(PREDICT_DIR, exist_ok=True)\n","\n","pred_df.to_csv(os.path.join(PREDICT_DIR, 'prediction.csv'), index=False)"],"id":"8f98cd03-5a99-4911-a72e-bc81e49c18be"},{"cell_type":"code","execution_count":31,"metadata":{"id":"SX6apf0nRz1Y","executionInfo":{"status":"ok","timestamp":1669029615663,"user_tz":-540,"elapsed":1090,"user":{"displayName":"hs L","userId":"04521576200392151172"}}},"outputs":[],"source":["# pred_df.to_csv('prediction1.csv')"],"id":"SX6apf0nRz1Y"},{"cell_type":"code","source":[],"metadata":{"id":"TTjnyv8j6tGZ"},"id":"TTjnyv8j6tGZ","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}